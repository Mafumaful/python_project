{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal LM: self-attention + ffn\n",
    "\n",
    "![decoder](./../image/Decoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([3, 4])\n",
      "before decoder torch.Size([3, 4])\n",
      "after decoder torch.Size([3, 4, 64])\n",
      "0th x shape torch.Size([3, 4, 64])\n",
      "1th x shape torch.Size([3, 4, 64])\n",
      "2th x shape torch.Size([3, 4, 64])\n",
      "3th x shape torch.Size([3, 4, 64])\n",
      "4th x shape torch.Size([3, 4, 64])\n",
      "torch.Size([3, 4, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0317, 0.1421, 0.0564, 0.1285, 0.0365, 0.1562, 0.0980, 0.0621,\n",
       "          0.0408, 0.0440, 0.1040, 0.0997],\n",
       "         [0.0479, 0.0925, 0.0254, 0.1728, 0.0583, 0.1789, 0.1241, 0.0221,\n",
       "          0.0248, 0.0808, 0.0968, 0.0756],\n",
       "         [0.0431, 0.0758, 0.0206, 0.1860, 0.0403, 0.1420, 0.1442, 0.0248,\n",
       "          0.0288, 0.0702, 0.1299, 0.0944],\n",
       "         [0.0370, 0.0825, 0.0203, 0.2120, 0.0398, 0.1552, 0.1327, 0.0206,\n",
       "          0.0260, 0.0679, 0.1268, 0.0792]],\n",
       "\n",
       "        [[0.0929, 0.0690, 0.1036, 0.0735, 0.0419, 0.1938, 0.0473, 0.0289,\n",
       "          0.1132, 0.0743, 0.0304, 0.1311],\n",
       "         [0.0756, 0.0650, 0.1395, 0.0889, 0.0414, 0.1910, 0.0485, 0.0263,\n",
       "          0.1188, 0.0743, 0.0263, 0.1044],\n",
       "         [0.0643, 0.0724, 0.1088, 0.0915, 0.0437, 0.2451, 0.0373, 0.0203,\n",
       "          0.1137, 0.0747, 0.0276, 0.1006],\n",
       "         [0.0730, 0.0809, 0.1183, 0.0893, 0.0377, 0.2379, 0.0497, 0.0213,\n",
       "          0.0756, 0.0707, 0.0351, 0.1104]],\n",
       "\n",
       "        [[0.0669, 0.1487, 0.0986, 0.1311, 0.0246, 0.1026, 0.0368, 0.0524,\n",
       "          0.0649, 0.0688, 0.1197, 0.0849],\n",
       "         [0.0669, 0.1487, 0.0986, 0.1311, 0.0246, 0.1026, 0.0368, 0.0524,\n",
       "          0.0649, 0.0688, 0.1197, 0.0849],\n",
       "         [0.0671, 0.1707, 0.1111, 0.1137, 0.0284, 0.1084, 0.0298, 0.0542,\n",
       "          0.0591, 0.0677, 0.1049, 0.0849],\n",
       "         [0.0662, 0.1535, 0.0941, 0.1002, 0.0257, 0.0872, 0.0448, 0.0754,\n",
       "          0.0745, 0.0791, 0.1048, 0.0945]]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "\n",
    "class SimpleDecoderLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim : int, head_num : int, attention_dropout_rate: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.head_num = head_num\n",
    "        self.head_dim = hidden_dim // head_num # 整除关系\n",
    "        \n",
    "        # layer (mha, ffn)\n",
    "        # mha\n",
    "        self.q = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.k = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.v = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.o = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.dropout_att = nn.Dropout(attention_dropout_rate)\n",
    "        self.att_ln = nn.LayerNorm(hidden_dim, eps=1e-7)\n",
    "        \n",
    "        # ffn\n",
    "        self.up_proj = nn.Linear(hidden_dim, hidden_dim * 4) # (swishGLU, ) 8 / 3\n",
    "        self.down_proj = nn.Linear(hidden_dim * 4, hidden_dim)\n",
    "        self.act_fn = nn.GELU()\n",
    "        self.dropout_ffn = nn.Dropout(1e-1)\n",
    "        self.ffn_ln = nn.LayerNorm(hidden_dim, eps=1e-7)\n",
    "        \n",
    "    def attention_layer(self, query, key, value, attention_mask = None):\n",
    "        # output (b, s, h)\n",
    "        key = key.transpose(2, 3) # (b, head_num, head_dim, seq)\n",
    "        attention_weight = query @ key / math.sqrt(self.head_dim)\n",
    "        \n",
    "        if attention_mask is not None:\n",
    "            attention_mask = attention_mask.tril()\n",
    "            attention_weight = attention_weight.masked_fill(\n",
    "                attention_mask == 0,\n",
    "                float(\"-inf\")\n",
    "            )\n",
    "        else:\n",
    "            attention_mask = torch.ones_like(attention_weight).tril()\n",
    "            attention_weight = attention_weight.masked_fill(\n",
    "                attention_mask == 0,\n",
    "                float(\"-inf\")\n",
    "            )\n",
    "        \n",
    "        attention_weight = torch.softmax(attention_weight, dim = -1)\n",
    "        attention_weight = self.dropout_att(attention_weight)\n",
    "        mid_out = attention_weight @ value\n",
    "        \n",
    "        \n",
    "        mid_out = mid_out.transpose(1, 2).contiguous()\n",
    "        b, s, _, _ = mid_out.size()\n",
    "        mid_out = mid_out.view(b, s, -1) # concat\n",
    "        \n",
    "        output = self.o(mid_out)\n",
    "        return output\n",
    "    \n",
    "    def mha(self, x, mask = None):\n",
    "        # (b, s, h) -> (b, head_num, s, head_dim)\n",
    "        batch, seq_len, _ = x.size()\n",
    "        \n",
    "        Q = self.q(x)\n",
    "        K = self.k(x)\n",
    "        V = self.v(x) # (b, s, h)\n",
    "        \n",
    "        # (b, s, h) -> (b, head_num, s, head_dim)\n",
    "        q_state = Q.view(batch, seq_len, self.head_num, self.head_dim).transpose(1, 2)\n",
    "        k_state = K.view(batch, seq_len, self.head_num, self.head_dim).transpose(1, 2)\n",
    "        v_state = V.view(batch, seq_len, self.head_num, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        output = self.attention_layer(q_state, k_state, v_state, mask)\n",
    "        \n",
    "        # post norm (b, s, h)\n",
    "        return output\n",
    "    \n",
    "    def ffn(self, x):\n",
    "        up = self.up_proj(x)\n",
    "        up = self.act_fn(up)\n",
    "        down = self.down_proj(up)\n",
    "        # # dropout\n",
    "        # down = self.dropout_ffn(down)\n",
    "        # post layernorm\n",
    "        return self.ffn_ln(x + down)\n",
    "    \n",
    "    def forward(self, x, attention_mask = None):\n",
    "        # (s, h)\n",
    "        x = self.mha(x, attention_mask)\n",
    "        x = self.ffn(x)\n",
    "        return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "        self.layer_list = nn.ModuleList([\n",
    "            SimpleDecoderLayer(64, 8) for i in range(5)\n",
    "        ])\n",
    "        \n",
    "        self.emb = nn.Embedding(12, 64)\n",
    "        self.out = nn.Linear(64, 12)\n",
    "    \n",
    "    def forward(self, x, mask = None):\n",
    "        # (3, 4)\n",
    "        print(\"before decoder\", x.shape)\n",
    "        x = self.emb(x)\n",
    "        print(\"after decoder\", x.shape)\n",
    "        for i, l in enumerate(self.layer_list):\n",
    "            x = l(x, mask)\n",
    "            print(f\"{i}th x shape\", x.shape)\n",
    "            \n",
    "        print(x.shape)\n",
    "        output = self.out(x)\n",
    "        return torch.softmax(output, dim = -1)\n",
    "        \n",
    "# (3, 4)\n",
    "x = torch.randint(low = 0, high = 12, size = (3, 4))\n",
    "print(\"x shape:\", x.shape)\n",
    "net = Decoder()\n",
    "# (3, 4) -unsqueeze-> (3, 1, 4) -unsqueeze-> (3, 1, 1, 4) -repeat-> (3, 8, 4, 4)\n",
    "mask = (\n",
    "    torch.tensor([[1, 1, 1, 1], [1, 1, 0, 0], [1, 0, 0, 0]]).unsqueeze(1).unsqueeze(2).repeat(1, 8, 4, 1)\n",
    ")\n",
    "net(x, mask)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmdrive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
