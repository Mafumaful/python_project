{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=20, out_features=20, bias=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Linear(20, 20)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2326,  0.1785, -1.2490, -0.7306, -0.2291,  0.5594, -1.5559, -1.0116,\n",
       "         -1.1620, -1.0997, -0.2715, -0.4577, -0.2467,  1.1738, -0.8826, -1.0207,\n",
       "          0.4757, -0.5631, -1.6778, -0.7757],\n",
       "        [-0.1527, -1.1700, -1.4510, -0.0490,  1.1780,  0.4239,  0.2479, -1.3563,\n",
       "          0.0314, -0.6898, -0.0330, -0.0472,  0.8067,  0.5678,  1.2402, -1.0382,\n",
       "          0.1232, -1.3979,  2.4194, -1.2689]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(2, 20)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1000, -0.4543, -0.4174,  1.0990, -0.0654,  0.1410, -0.1766,  0.6177,\n",
      "          0.1771, -0.3112,  0.5409, -0.2009, -0.3068,  0.1291, -0.1453,  0.3107,\n",
      "         -0.0550,  0.2477,  0.6072, -0.0276],\n",
      "        [-0.4808,  0.9679, -0.5283, -0.8774, -0.1210, -0.4861, -0.4526,  0.0085,\n",
      "          0.4329,  0.1407, -0.7759, -0.4490, -0.2439,  0.4977,  0.2351, -0.0262,\n",
      "          0.1187, -0.8186,  0.5970, -0.3676]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(m(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.1027, -0.8514, -1.8332, -0.9616],\n",
      "         [-0.0031, -0.2130,  1.0061,  0.1961],\n",
      "         [ 0.1619, -0.6942, -2.0076, -0.3162]]])\n",
      "tensor([[-1.7367, -0.0734,  0.9158,  0.2476,  1.3631],\n",
      "        [-0.4264,  0.3656, -0.9017, -0.4464,  0.3248],\n",
      "        [ 0.2003,  0.3338, -0.4573,  1.0601,  1.5355],\n",
      "        [ 0.2081, -0.6021, -0.0551,  1.4546, -0.0076]])\n",
      "tensor([[[-3.8560, -0.4986,  3.5846, -2.4414, -0.2180],\n",
      "         [ 0.3385,  0.1401, -0.2817,  1.4463,  1.4701],\n",
      "         [-0.4531, -0.7454,  1.7097, -2.2381, -3.0850]]])\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.randn(1, 3, 4)\n",
    "print(tensor1)\n",
    "tensor2 = torch.randn(4, 5)\n",
    "print(tensor2)\n",
    "output = torch.matmul(tensor1, tensor2)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6,  9],\n",
      "        [ 9, 12],\n",
      "        [12, 15]])\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.tensor(\n",
    "    [[1, 4],\n",
    "    [2, 5],\n",
    "    [3, 6]]\n",
    ")\n",
    "\n",
    "tensor2 = torch.tensor(\n",
    "    [[2, 1],\n",
    "    [1, 2]]\n",
    ")\n",
    "\n",
    "print(torch.matmul(tensor1, tensor2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transpose test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0804,  0.6381, -1.5405],\n",
      "         [-0.2551, -0.2482,  1.1230]],\n",
      "\n",
      "        [[-0.5511, -0.7775, -1.2440],\n",
      "         [-1.1035,  1.0970, -0.0220]],\n",
      "\n",
      "        [[-1.1994, -0.1375,  0.3712],\n",
      "         [-0.4051,  0.2625,  1.8980]]])\n",
      "tensor([[[ 1.0804,  0.6381, -1.5405],\n",
      "         [-0.5511, -0.7775, -1.2440],\n",
      "         [-1.1994, -0.1375,  0.3712]],\n",
      "\n",
      "        [[-0.2551, -0.2482,  1.1230],\n",
      "         [-1.1035,  1.0970, -0.0220],\n",
      "         [-0.4051,  0.2625,  1.8980]]])\n",
      "torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 2, 3)\n",
    "print(x)\n",
    "x2 = torch.transpose(x, 0, 1)\n",
    "print(x2)\n",
    "print(x2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax dim=0:\n",
      " tensor([[0.1192, 0.1192],\n",
      "        [0.8808, 0.8808]])\n",
      "Softmax dim=1:\n",
      " tensor([[0.2689, 0.7311],\n",
      "        [0.2689, 0.7311]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Input tensor\n",
    "input_tensor = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "\n",
    "# Softmax along dim=0 (column-wise)\n",
    "softmax_dim0 = nn.Softmax(dim=0)\n",
    "output_dim0 = softmax_dim0(input_tensor)\n",
    "print(\"Softmax dim=0:\\n\", output_dim0)\n",
    "\n",
    "# Softmax along dim=1 (row-wise)\n",
    "softmax_dim1 = nn.Softmax(dim=1)\n",
    "output_dim1 = softmax_dim1(input_tensor)\n",
    "print(\"Softmax dim=1:\\n\", output_dim1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmdrive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
